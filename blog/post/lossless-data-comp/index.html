<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <title>Lossless Data Compression</title>
    <meta
      name="description"
      content="A comprehensive comparison and analysis of various lossless data compression algorithms, including ZIP, 7zip, XZ, Brotli, Zstandard, and ZPAQ."
    />
    <meta
      name="keywords"
      content="lossless data compression, ZIP, 7zip, XZ, Brotli, Zstandard, ZPAQ, compression algorithms, performance analysis"
    />
    <meta name="author" content="Gianni Rosato" />
    <meta name="robots" content="index, follow" />
    <meta
      name="googlebot"
      content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"
    />
    <meta
      name="bingbot"
      content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"
    />
    <meta property="og:title" content="Lossless Data Compression" />
    <meta
      property="og:description"
      content="A comprehensive comparison and analysis of various lossless data compression algorithms, including ZIP, 7zip, XZ, Brotli, Zstandard, and ZPAQ."
    />
    <meta property="og:type" content="article" />
    <meta
      property="og:url"
      content="https://giannirosato.com/blog/lossless-data-comp"
    />
    <link href="/static/favicon.webp" rel="icon" />
    <link href="/static/css/main.css" rel="stylesheet" />
    <link href="/static/css/markdown.css" rel="stylesheet" />
    <title>
      Lossless Data Compression
    </title>

    <link href="/static/favicon.webp" rel="icon" />
    <link href="/static/css/main.css" rel="stylesheet" />
    <link href="/static/css/markdown.css" rel="stylesheet" />
    <script
      defer
      src="https://cloud.umami.is/script.js"
      data-website-id="ed9fd2cd-67dd-4524-ad11-1810fb677e29"
    ></script>
  </head>

  <body>
    <div class="center">
      <div class="post-header">
        <div class="title" style="display: inline-grid">
          Lossless Data Compression
        </div>
        <a class="back" href="/blog/">back</a>
        <div class="date">Oct 2, 2023</div>

        <a class="tag" href="/blog/tag/projects/">projects</a>
      </div>
      <div class="button-container-left">
        <a href="/blog/" class="button-blog">Back</a>
        <a href="/" class="button-blog">Home</a>
      </div>
      <h1 id="lossless-data-compression">Lossless Data Compression</h1>
      <p>
        While I&#39;ve covered image compression a decent amount in these sorts
        of blog posts, I wanted to dive into generic lossless data compression a
        bit more to see what this interesting realm of compression has to offer.
        Inspired by the many other existing lossless data compression
        comparisons, I wanted to approach this with visualizations similar to
        the ones I provide in my image codec comparisons. Because lossless data
        compression doesn&#39;t discard data, these graphs plot time vs.
        compressed size, allowing you to compare the various compression steps
        of lossless data compression algorithms relative to the time taken to
        compress/decompress.
      </p>
      <h1 id="methodology-algorithms">Methodology &amp; Algorithms</h1>
      <p>
        I want to make it clear upfront that I did <em>not</em> thoroughly test
        every single available compression algorithm under the sun, but instead
        hand-picked a couple that I found interesting. Notably not present are
        gzip &amp; bzip2; gzip has an interesting history, but its use of
        Deflate &amp; LZ77 makes it pretty much identical to ZIP for all intents
        &amp; purposes. Bzip2 is interesting, but due to its age &amp;
        effectiveness compared to more modern compression algorithms, I found it
        less interesting than more modern options. It also decompresses slower
        than the more space-efficient XZ. Feel free to pique my interest in
        these two algorithms if you&#39;re interested in seeing them included.
      </p>
      <p>
        I must provide the usual disclaimer as well that my testing is
        non-scientific &amp; shouldn&#39;t inform your use of one technology
        over another. That being said, here are the formats I tested:
      </p>
      <ul>
        <li>ZIP (via 7zip)</li>
        <li>7zip</li>
        <li>XZ</li>
        <li>Brotli</li>
        <li>Zstandard</li>
        <li>zpaq</li>
      </ul>
      <p>
        &amp; here are the parameters I used for compression, often after
        archiving to a .tar:
      </p>
      <ul>
        <li>
          ZIP: <code>7zzs a -bso0 -tzip -mx[level] &quot;out&quot;
            &quot;input&quot;</code>
        </li>
        <li>
          7zip: <code>7zzs a -bso0 -mx[level] &quot;out&quot;
            &quot;input&quot;</code>
        </li>
        <li>
          XZ: <code>xz -q -q -T0 -k -[level] &quot;input&quot;
            &quot;out&quot;</code>
        </li>
        <li>
          Brotli: <code>brotli -q [level] &quot;input&quot; -o
            &quot;out&quot;</code>
        </li>
        <li>
          Zstandard: <code>zstd -q --ultra -[level] -T0 &quot;input&quot; -o
            &quot;out&quot;</code>
        </li>
        <li>
          zpaq: <code>zpaq a &quot;out&quot; &quot;input&quot; -m[level]</code>
        </li>
      </ul>
      <p>Finally, here are my system specs:</p>
      <pre
      >
<code class="lang-zsh">CPU: 16-core (8-mt/8-st) 13th Gen Intel Core i7-13700K (-MST AMCP-)
     speed/min/max: 888/800/5300:5400:4200 MHz Kernel: 6.5.5-zen1-1-zen x86_64
</code></pre
      >
      <p>
        If you&#39;d like to do a deeper dive into my methodology, I have my
        script <code>compression-plotter</code> available <a
          href="https://github.com/gianni-rosato/compression-plotter"
        >on GitHub</a>. Given you have all the dependencies, you are free to run
        it yourself to cross-reference any results you come up with against
        mine.
      </p>
      <p>
        I used a 1.0GB generic Wikipedia download for this test, which makes it
        text-specific. Now, let&#39;s dive into which algorithms I chose &amp;
        what they do.
      </p>
      <h3 id="zip-deflate">ZIP (Deflate)</h3>
      <p>
        Most modern variants of the tried &amp; true ZIP use the Deflate
        compression algorithm, which is also famously used in PNG. Deflate acts
        as a combination of LZ77 lossless coding &amp; Huffman coding, where it
        can first use LZ77 to find patterns in the data &amp; reduce redundancy.
        This is followed by using Huffman coding to assign smaller bit values to
        patterns found more frequently by LZ77.
      </p>
      <p>
        Considering ZIP came out in 1989, I don&#39;t expect it to be the
        strongest performer on this benchmark. I&#39;m interested to see how
        7zip&#39;s supposedly improved ZIP encoder fares against the other
        standards, though; as the 7zip website&#39;s homepage claims: &quot;For
        ZIP and GZIP formats, 7-Zip provides a compression ratio that is 2-10 %
        better than the ratio provided by PKZip and WinZip.&quot;
      </p>
      <p>
        ZIP is noteworthy for its nearly universal compatibility.
        &quot;Traditional ZIP&quot; (compression method 8) is limited to 4 GB,
        though most ZIP compressors use Deflate64(tm) (compression level 9 in
        the ZIP specification) to bypass this limitation.
      </p>
      <h3 id="7zip">7zip</h3>
      <p>
        Using the static 7zip binary for Linux, I benchmarked 7zip not initially
        very interested in its compression capabilities. However, as I continued
        to use it, I was impressed by its usability &amp; sane defaults; 7zip
        compression &amp; decompression both thread rather effectively, which
        makes the format <em>feel</em> very fast to work with even if system
        &amp; user time tell a slightly different story. It is supported just
        fine on my Arch Linux installation with GNOME, and it works on macOS by
        default. To open a 7zip (.7z) archive on Windows 10, you need the
        well-known <a href="https://www.7-zip.org/">7-Zip utility</a>.
      </p>
      <p>
        7zip is <em>mostly</em> based on LZMA &amp; LZMA2, though there is <a
          href="https://www.7-zip.org/7z.html"
        >a lot more going on</a> if you look deeper. LZMA2 is an improved
        version of LZMA, which itself is based on LZ77.
      </p>
      <h3 id="xz">XZ</h3>
      <p>
        XZ can only compress one file at a time, so making a tar archive of the
        files you&#39;d like to compress (if there are multiple) is necessary
        when using XZ. The XZ format itself is an improvement on LZMA, allowing
        for preprocessing filters similar to 7zip to increase the resulting
        archive&#39;s compression ratio. I&#39;ve been able to decompress
        .tar.xz archives on macOS &amp; Linux just fine, but Windows 10 needs
        7-Zip once again.
      </p>
      <h3 id="brotli">Brotli</h3>
      <p>
        Brotli was designed by Google, &amp; is commonly used as a compression
        format on the Web. It was released in late 2013, &amp; it is commonly
        used on the Web for content delivery. It is a core part of the .woff2
        Web Open Font Format, allowing web fonts to be smaller when sent to
        users as part of a website. It is not very common to pass around .tar.br
        files, so it is perfectly acceptable that such files aren&#39;t really
        compatible anywhere. Brotli is almost universally compatible across the
        Web, being supported by as much as 96% of the world wide web&#39;s
        users.
      </p>
      <p>
        Brotli is based on LZ77 &amp; Huffman coding, much like ZIP. It also
        uses context modeling to allow the use of multiple Huffman trees for the
        same alphabet in the same block; without getting into the weeds, this
        essentially means that based on the <em>context</em> of the data being
        compressed, it can be compressed more efficiently especially if it
        contains multiple different kinds of data.
      </p>
      <p>
        Brotli was co-authored &amp; partially developed by Jyrki Alakuijala,
        who also worked on JPEG XL &amp; jpegli. JPEG XL&#39;s metadata
        information can be uncompressed or Brotli-compressed.
      </p>
      <h3 id="zstandard">Zstandard</h3>
      <p>
        Zstandard is a compression algorithm by Facebook known for its extremely
        fast decompression speeds. It was released in early 2015 and is used in
        a variety of different contexts. It was designed to perform similarly to
        older Deflate-based compression algorithms like ZIP or gzip while being
        overall faster. In practice, it is said to compress similarly to pure
        LZMA while being much faster.
      </p>
      <p>
        While .tar.zst archives aren&#39;t going to be very popular to find on
        the Internet &amp; elsewhere, it is already a very popular tool for
        compression in the world of open-source software. It has been integrated
        into both the FreeBSD kernel &amp; the Linux kernel and is available as
        a filesystem compression method for the btrfs, squashfs, bcachefs, &amp;
        OpenZFS filesystems. All Arch Linux packages are compressed at zstd
        level 20, allowing Arch packages to be decompressed <em>14 times</em>
        faster than when Arch used XZ at the cost of an average 0.8% filesize
        increase. It is popular in the game emulation scene as well, as many
        game file formats for emulating console games support zstd compression.
        The ZIP file format actually supports Zstandard in compression level 93
        since version 6.3.8 which was published in 2020. Content encoding using
        zstd is supported since Chromium 118 behind an experimental flag,
        meaning it might compete with Brotli on the web in the future.
        Apple&#39;s LZFSE algorithm is purportedly similar to Zstandard
        compression level 6.
      </p>
      <h3 id="zpaq">ZPAQ</h3>
      <p>
        I know much less about ZPAQ, but from what I can glean it uses a
        multitude of different compression algorithms to try to achieve the best
        size-to-compression-time ratio possible while producing the smallest
        possible archives without much concern given to decompression
        performance. On the <a href="https://mattmahoney.net/dc/zpaq.html"
        >official ZPAQ website</a>, it looks like it is designed for
        &quot;realistic backups that have a lot of duplicate files and a lot of
        already compressed files.&quot;
      </p>
      <p>
        What I find very cool about ZPAQ is that it is an <em>incremental</em>
        journaling archiver, meaning you can add files to an existing archive
        based on if they were changed or not which reduces the time needed to
        wait for a new backup to finish. If other tools here are capable of
        this, I have not seen it advertised, but this is particularly cool for
        ZPAQ since it is so focused on compression ratio &amp; in practice, this
        kind of feature may reduce the burden imposed by long compression times.
        ZPAQ archives aren&#39;t handled by default on my Linux installation in
        Nautilus.
      </p>
      <h1 id="results">Results</h1>
      <h3 id="compression">Compression</h3>
      <p>
        Here are my compression performance results, measured in real time. This
        graph uses a logarithmic horizontal scale factor:
      </p>
      <picture>
        <img
          alt="compression_realtime_results"
          src="/static/images/compression_realtime.svg"
          width="640"
          height="489"
          loading="lazy"
        />
      </picture>
      <p><strong>My personal takeaways from this test:</strong></p>
      <ul>
        <li>
          This is very much not fair to Brotli, as the reference encoder can
          only use 1 thread at a time, disadvantaging it in real
          clock-on-the-wall time comparisons like this one. Wait for the next
          test
        </li>
        <li>
          Zstandard is indeed competitive with xz &amp; 7zip, although it
          isn&#39;t quite as good. Higher effort ZPAQ pulls far ahead of
          everything
        </li>
        <li>
          ZIP is, predictably, behind the pack by a good amount. Can&#39;t say
          I&#39;m surprised :P
        </li>
        <li>
          XZ extreme vs. normal doesn&#39;t seem to have a meaningful effect on
        </li>
        <li>
          Low-effort Zstandard is <em>really</em> fast, and competes with ZIP
          despite being much faster. Mission accomplished?
        </li>
      </ul>
      <p>
        Here are my compression performance results, measured in <em>user +
          system</em> time (the time the computer uses across its resources,
        added up). This graph uses a logarithmic horizontal scale factor:
      </p>
      <picture>
        <img
          alt="compression_usrtime_results"
          src="/static/images/compression_usrtime.svg"
          width="640"
          height="489"
          loading="lazy"
        />
      </picture>
      <p><strong>My personal takeaways from this test:</strong></p>
      <ul>
        <li>
          Not sure why I omitted ZPAQ from this test. Either way, we know from
          the previous test it probably would have looked the same considering
          it is multithreaded
        </li>
        <li>
          Now, Brotli looks much more competitive. Not sure if allowing the
          other encoders to use multiple threads hampers their performance at
          all, though I don&#39;t know why it would
        </li>
        <li>This makes zstd look much more competitive with XZ &amp; 7zip</li>
        <li>
          ZIP still lags behind. Using this older Deflate algorithm isn&#39;t
          going to save you any compute resources compared to modern options
          like Brotli &amp; zstd
        </li>
      </ul>
      <h3 id="decompression">Decompression</h3>
      <p>
        Evaluating any of these compression standards for practical use means
        you must take decompression into account. Let&#39;s look at the first
        batch of results for real time, where I tested decompression performance
        for the <strong>lowest &amp; highest levels of compression
          effort</strong> for each standard. Once again, this graph uses a
        logarithmic horizontal scale factor:
      </p>
      <picture>
        <img
          alt="decompression_realtime_results"
          src="/static/images/decompression_realtime.svg"
          width="640"
          height="489"
          loading="lazy"
        />
      </picture>
      <p><strong>My personal takeaways from this test:</strong></p>
      <ul>
        <li>
          Yikes, not looking good for ZPAQ in this test. It definitely showed
          its strengths before as an archival format, but as anything else, it
          doesn&#39;t look viable
        </li>
        <li>
          The gap between XZ &amp; 7zip is pretty astonishing. I&#39;d like to
          see in the next test if this has to do with 7zip taking advantage of
          multiple threads more effectively, but either way, 7zip clearly has
          the better user experience
        </li>
        <li>
          I&#39;m once again left wondering how much better Brotli will perform
          when given the opportunity to level the playing field with the other
          standards
        </li>
        <li>ZIP still isn&#39;t good</li>
        <li>
          Considering decompression performance is one of Zstandard&#39;s
          highlights, 7zip makes a strong case for being a better choice if
          Zstandard can&#39;t compete in the next test
        </li>
        <li>
          That third pink X next to the one closest to the bottom for XZ is
          decompression performance for the &quot;extreme&quot; version of the
          highest compression level. Not much difference, again
        </li>
      </ul>
      <p>
        Finally, here are the user + sys time results for decompression. This
        should tell us a more complete story about why 7zip is so fast in real
        time. This graph uses a logarithmic horizontal scale factor:
      </p>
      <picture>
        <img
          alt="decompression_usrtime_results"
          src="/static/images/decompression_usrtime.svg"
          width="640"
          height="489"
          loading="lazy"
        />
      </picture>
      <p><strong>My personal takeaways from this test:</strong></p>
      <ul>
        <li>ZPAQ is still not great</li>
        <li>
          The gap has closed a <em>lot</em> between 7zip &amp; XZ, showing that
          under the hood, 7zip is really just a more advanced XZ with more
          thoughtfully designed utilities optimized for desktop use where a
          decoder can comfortably make use of multi-threading on powerful
          systems
        </li>
        <li>
          ZIP isn&#39;t that bad compared to 7zip &amp; XZ! This is the first
          <em>real</em> win ZIP pulls out, in my opinion, considering weaker
          systems may see performance more similar to this test for real time
          decompression than my previous test
        </li>
        <li>
          Brotli is good, but zstd is clearly in a class by itself. Now it makes
          a lot more sense why decompression performance was emphasized so much,
          and why zstd is the optimal choice for filesystem compression
        </li>
      </ul>
      <h1 id="conclusion">Conclusion</h1>
      <p>
        My conclusion overall is that there really are different scenarios where
        each format shines. I&#39;ll explain for each format:
      </p>
      <p>
        Firstly, <strong>ZPAQ</strong> is going to be my choice for computer
        backups if I ever do them (I often don&#39;t). The incremental option
        alongside the incredible compression ratio makes it the best option for
        this use case, in my opinion, given you&#39;ll be willing to allow it to
        take its sweet time as it decompresses. For a backup format, I don&#39;t
        think that&#39;s the biggest deal in the world anyway.
      </p>
      <p>
        <strong>7zip</strong> seems like the best option for general desktop
        use, and if you&#39;re distributing files, providing <code>.7z</code>
        archives might not be a terrible idea if you&#39;re looking to phase out
        ZIP to save server space &amp; bandwidth while maintaining
        compatibility. The last holdout for support is Android, as Windows 11
        can now decompress 7zip archives. 7zip&#39;s widespread support as well
        as its good performance earn it this position. Did you know even iOS can
        preview the contents of 7zip archives?
      </p>
      <p>
        <strong>XZ</strong> is a bit of a black sheep here in a world where 7zip
        exists. 7zip &amp; XZ are both open source, too. Tell me if XZ has some
        hidden strengths I&#39;m missing.
      </p>
      <p>
        <strong>Brotli</strong> as a replacement for simpler algorithms on the
        Web for content delivery makes complete sense. It decompresses fast
        &amp; compresses well, and can be parallelized using other
        implementations to optimize real time encode performance. In the
        meantime, servers are more concerned with user &amp; system time, so
        those graphs are likely more salient when considering Brotli performance
        where it is applicable.
      </p>
      <p>
        <strong>Zstandard</strong> is what I&#39;d consider to be the <em
        >future</em> of all of the above categories. In certain scenarios, if it
        takes off as a content delivery format, I could see it replacing Brotli
        if the benefits of super-fast &amp; super-light decode improve the
        responsiveness of web pages &amp; are worth sacrificing a bit of
        compression ratio. When using the much higher effort settings, it
        actually beats Brotli on all accounts. I&#39;d be happy to pass around
        <code>.tar.zst</code> archives in the future to replace 7zip &amp; ZIP,
        making speedy decode a reality on systems of all different measures of
        compute performance. I&#39;m glad Zstandard is making its way as a great
        format to use in the FOSS community for innovative new implementations
        of compression like filesystem compression &amp; accessible package
        compression that doesn&#39;t tax your CPU when decoding, but I&#39;d
        personally like to see its use cases expand in the future.
      </p>
      <p>
        <strong>ZIP</strong>&#39;s Deflate implementation is very clearly useful
        for one thing: compatibility. I&#39;m glad the Deflate patent has
        expired, otherwise I&#39;d be much more disappointed in ZIP&#39;s
        standardization as the default compression archive format in most
        situations. Personally, for the time being, I&#39;m just glad we
        didn&#39;t unintentionally standardize around <em>uncompressed</em>
        archives, as I&#39;d be willing to bet many don&#39;t know ZIPs are
        actually compressed.
      </p>
      <p>
        What do you think of my results? Is there anything I missed or could
        have done better? Should I include bzip2 or some other algorithm next
        time? Let me know. Thank you for reading!
      </p>

      <div class="sponsor-widget">
        <a href="https://github.com/gianni-rosato" class="profile-section">
          <img
            src="/static/images/my_gh_profile.avif"
            alt="Gianni Rosato"
            class="profile-photo"
          />
        </a>
        <div class="content-section">
          <h3 class="profile-name">Sponsor Me on GitHub Sponsors</h3>
          Help support my open source efforts - a little goes a long way!
        </div>
        <a
          href="https://github.com/sponsors/gianni-rosato?o=esc"
          class="sponsor-button"
        >
          <svg
            class="heart-icon"
            xmlns="http://www.w3.org/2000/svg"
            width="16"
            height="16"
            fill="none"
            viewBox="0 0 0.48 0.48"
          >
            <path
              stroke="#000"
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width=".043"
              d="M.24.11C.202.063.138.05.09.09a.118.118 0 0 0-.017.161 1.798 1.798 0 0 0 .164.162.01.01 0 0 0 .006 0L.25.408C.28.38.376.294.407.252A.117.117 0 0 0 .39.092C.341.05.278.063.24.108Z"
              clip-rule="evenodd"
              style="stroke: oklch(70.2%0.35 328.4); stroke-opacity: 1"
            />
          </svg>
          Sponsor
        </a>
      </div>
      <p>
        <a href="https://elk.zone/disobey.net/@gianni">Mastodon</a> | <a
          href="https://matrix.to/#/@computerbustr:matrix.org"
        >Matrix</a>
      </p>
    </div>
  </body>
</html>
